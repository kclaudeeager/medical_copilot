{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG using Meta AI Llama-3\n",
    "\n",
    "\n",
    "<img src=\"./resources/rag_architecture.png\" width=800px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core import PromptTemplate\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import VectorStoreIndex, ServiceContext, SimpleDirectoryReader\n",
    "\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index.core import Settings\n",
    "import qdrant_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows nested access to the event loop\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your documents in this directory, you can drag & drop\n",
    "input_dir_path = '/teamspace/studios/this_studio/medical_documents'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name=\"chat_with_docs\"\n",
    "\n",
    "client = qdrant_client.QdrantClient(\n",
    "    host=\"localhost\",\n",
    "    port=6333\n",
    ")\n",
    "\n",
    "def create_index(documents):\n",
    "    vector_store = QdrantVectorStore(client=client, collection_name=collection_name)\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        documents,\n",
    "        storage_context=storage_context,\n",
    "    )\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfc6411e42df4944b937cce5afddb207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/779 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f9f693b264d4fb7a64b7157465670cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f532ac70a8425eae0a2412acd519b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72af98bb854841c0a7b42c91e58ef533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb46b6936724a0c93534236793e3e4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971561c1647e4d9bbd596438785fb28e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# setup llm & embedding model\n",
    "llm=Ollama(model=\"llama3:8b-instruct-q4_1\", request_timeout=120.0)\n",
    "# embed_model = HuggingFaceEmbedding( model_name=\"Snowflake/snowflake-arctic-embed-m\", trust_remote_code=True)\n",
    "embed_model = HuggingFaceEmbedding( model_name=\"BAAI/bge-large-en-v1.5\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f5f601b1d7544ffa4848bd46b8b380a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/5229 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ef9df5a2e343e09e8d0ef6ea74aa3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95672ef84a34ed2ad72d57d2f8807c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b8ec12b2fd342fab9480263800cd879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf4802189d7496bbb0177d829514f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1673 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Response: I'm happy to assist with diagnostic support. Please provide me with the patient's symptoms, medical history, and local disease data. I'll do my best to suggest a diagnosis and treatment options based on the information provided.\n",
      "\n",
      "Please note that I'm an AI-powered clinical assistant, and while I can provide valuable insights and suggestions, it's essential to remember that I am not a substitute for a qualified healthcare professional. A comprehensive diagnosis requires careful consideration of various factors, including medical history, physical examination findings, laboratory results, and other relevant information.\n",
      "\n",
      "To get started, please provide the following information:\n",
      "\n",
      "* Symptoms: Please describe the patient's symptoms in detail, including any relevant dates or duration of symptoms.\n",
      "* Medical history: Please provide a brief summary of the patient's medical history, including any significant conditions, surgeries, allergies, or previous diagnoses.\n",
      "* Local disease data: If available, please share local disease trends, outbreaks, or seasonal patterns that may be relevant to the patient's symptoms.\n",
      "\n",
      "Once I have this information, I'll do my best to:\n",
      "\n",
      "1. Identify potential diagnoses based on the provided symptoms and medical history.\n",
      "2. Suggest treatment options for each possible diagnosis.\n",
      "3. Provide follow-up consultation questions for the healthcare provider to ask the patient to ensure a comprehensive diagnosis.\n",
      "4. Offer classifications of possible diseases, including differential diagnoses (similar conditions to rule out).\n",
      "5. Ask further clarifying questions that the doctor should consider, such as lifestyle factors, prior medical history, or exposure to local disease trends, to refine the diagnosis.\n",
      "\n",
      "Please provide the necessary information, and I'll get started on assisting with diagnostic support.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "loader = SimpleDirectoryReader(\n",
    "            input_dir = input_dir_path,\n",
    "            required_exts=[\".pdf\"],\n",
    "            recursive=True\n",
    "        )\n",
    "docs = loader.load_data()\n",
    "\n",
    "# Creating an index over loaded data\n",
    "Settings.embed_model = embed_model\n",
    "try:\n",
    "    index = create_index(docs)\n",
    "    print('Using Qdrant collection')\n",
    "except:\n",
    "    index = VectorStoreIndex.from_documents(docs, show_progress=True)\n",
    "\n",
    "# Create the query engine, where we use a cohere reranker on the fetched nodes\n",
    "Settings.llm = llm\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "# ====== Customise prompt template ======\n",
    "broad_prompt = '''\n",
    "You are an expert clinical assistant AI. Your task is to help healthcare providers with diagnostic support based on patient symptoms, medical history, and local disease data.\n",
    "\n",
    "- If the patient's symptoms match a known diagnosis based on your pre-existing knowledge or provided documents, suggest the diagnosis and treatment options.\n",
    "- Otherwise, use the search tool to retrieve relevant medical information.\n",
    "- In addition to diagnosis, suggest follow-up consultation questions for the healthcare provider to ask the patient to ensure a comprehensive diagnosis.\n",
    "- Provide classifications of possible diseases based on the symptoms, including differential diagnoses (similar conditions to rule out).\n",
    "- Ensure to ask further clarifying questions that the doctor should consider, such as lifestyle factors, prior medical history, or exposure to local disease trends, to refine the diagnosis.\n",
    "- If the user does not provide all the necessary information (e.g., symptoms, medical history, or location), ask them to specify the missing fields.\n",
    "'''\n",
    "qa_prompt_tmpl =  PromptTemplate(broad_prompt)\n",
    "\n",
    "query_engine.update_prompts(\n",
    "    {\"response_synthesizer:text_qa_template\": qa_prompt_tmpl}\n",
    ")\n",
    "\n",
    "# Generate the response\n",
    "# Generate the response with an example query\n",
    "response = query_engine.query(\"What are the potential diagnoses for a patient with a cough, fever, and asthma?\",)\n",
    "\n",
    "# Print the generated response\n",
    "print(\"Generated Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I'm happy to assist with diagnostic support. Please provide me with the patient's symptoms, medical history, and local disease data. I'll do my best to suggest a diagnosis and treatment options based on the information provided.\n",
       "\n",
       "Please note that I'm an AI-powered clinical assistant, and while I can provide valuable insights and suggestions, it's essential to remember that I am not a substitute for a qualified healthcare professional. A comprehensive diagnosis requires careful consideration of various factors, including medical history, physical examination findings, laboratory results, and other relevant information.\n",
       "\n",
       "To get started, please provide the following information:\n",
       "\n",
       "* Symptoms: Please describe the patient's symptoms in detail, including any relevant dates or duration of symptoms.\n",
       "* Medical history: Please provide a brief summary of the patient's medical history, including any significant conditions, surgeries, allergies, or previous diagnoses.\n",
       "* Local disease data: If available, please share local disease trends, outbreaks, or seasonal patterns that may be relevant to the patient's symptoms.\n",
       "\n",
       "Once I have this information, I'll do my best to:\n",
       "\n",
       "1. Identify potential diagnoses based on the provided symptoms and medical history.\n",
       "2. Suggest treatment options for each possible diagnosis.\n",
       "3. Provide follow-up consultation questions for the healthcare provider to ask the patient to ensure a comprehensive diagnosis.\n",
       "4. Offer classifications of possible diseases, including differential diagnoses (similar conditions to rule out).\n",
       "5. Ask further clarifying questions that the doctor should consider, such as lifestyle factors, prior medical history, or exposure to local disease trends, to refine the diagnosis.\n",
       "\n",
       "Please provide the necessary information, and I'll get started on assisting with diagnostic support."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(str(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ❗️❗️ Make sure you clear GPU memory by clicking on Restart button above, if you want to use Streamlit from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jul  5 09:52:53 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A10G                    Off | 00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   38C    P0              65W / 300W |   5956MiB / 23028MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# check GPU usage\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
